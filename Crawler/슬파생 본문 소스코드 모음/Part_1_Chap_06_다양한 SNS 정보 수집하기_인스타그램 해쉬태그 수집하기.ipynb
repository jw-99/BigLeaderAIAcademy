{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# 인스타 그램의 해쉬태그 수집하기 - by 서진수\n",
    "##########################################################################\n",
    "#Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import unicodedata   # 인스타그램의 해시태그 수집 중 자음/모음 분리현상 방지용 모듈\n",
    "\n",
    "#Step 2. 사용자에게 필요한 정보들을를 입력 받습니다.\n",
    "print(\"=\" *70)\n",
    "print(\"   이 크롤러는 인스타그램의 해시태그 정보를 수집합니다\")\n",
    "print(\"   본 제품은 서진수가 교육용으로 특별 제작했으며 \")\n",
    "print(\"   용도외의 사용으로 저작권을 침해하는 행위는 불법입니다\")\n",
    "print(\"   본 제품에 대한 문의는 seojinsu@gmail.com 으로 보내주세요~^^\")\n",
    "print(\"=\" *70)\n",
    "\n",
    "v_id = input(\"1.인스타그램의 ID를 입력하세요: \")\n",
    "v_passwd = input(\"2.인스타그램의 비밀번호를 입력하세요: \")\n",
    "query_txt = input(\"3.검색할 해쉬태그를 입력하세요(예: 강남맛집): \")\n",
    "cnt = int(input('4.크롤링 할 건수는 몇건입니까?: '))\n",
    "real_cnt = math.ceil(cnt / 30)\n",
    "\n",
    "f_dir=input('5.파일이 저장될 경로만 쓰세요(기본경로 : c:\\\\temp\\\\ ) : ')\n",
    "if f_dir =='' :\n",
    "    f_dir = \"c:\\\\temp\\\\\"\n",
    "\n",
    "#Step 3. 결과를 저장할 폴더명과 파일명을 설정하고 폴더를 생성합니다.\n",
    "s_time = time.time( )\n",
    "query_txt2 = '인스타그램'\n",
    "\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s+'-'+query_txt2+'-'+query_txt)\n",
    "f_name=f_dir+s+'-'+query_txt2+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.txt'\n",
    "\n",
    "# Step 4. 인스타그램 자동 로그인 하기\n",
    "chrome_path = \"c:/temp/chromedriver_85/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "\n",
    "driver.get(\"https://www.instagram.com/\")\n",
    "time.sleep(random.randrange(1,5))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"요청하신 데이터를 추출중이오니 잠시만 기다려 주세요~~~~^^\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#ID와 비번 입력후 로그인하기\n",
    "eid = driver.find_element_by_name('username')\n",
    "for a in v_id :\n",
    "        eid.send_keys(a)\n",
    "        time.sleep(0.3)\n",
    "epwd = driver.find_element_by_name('password')\n",
    "for b in v_passwd :\n",
    "        epwd.send_keys(b)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]/button/div').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Step 5. 검색할 해쉬태그 입력하기\n",
    "#로그인 정보 나중에 저장하기\n",
    "driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/div/div/div/button').click()\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[4]/div/div/div/div[3]/button[2]').click()\n",
    "time.sleep(1)\n",
    "\n",
    "# 검색할 키워드 입력하기\n",
    "element = driver.find_element_by_xpath('''//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input''')\n",
    "\n",
    "for c in query_txt :\n",
    "    element.send_keys(c)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "time.sleep(2)\n",
    "driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div[2]/div/a[1]/div').click()\n",
    "\n",
    "# 자동 스크롤다운 함수\n",
    "def scroll_down(driver):\n",
    "  driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "  time.sleep(5)\n",
    "\n",
    "i = 1\n",
    "while (i <= real_cnt):\n",
    "      scroll_down(driver) \n",
    "      i += 1\n",
    "\n",
    "# Step 6. 전체 게시물의 원본 URL 추출하기\n",
    "item=[]\n",
    "count = 0\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "all = soup.find('article','KC1QD').find_all('a')\n",
    "\n",
    "for i in all:    \n",
    "    url = i['href']\n",
    "    item.append(url)  \n",
    "    count += 1\n",
    "    \n",
    "    if count == cnt :\n",
    "        break\n",
    "\n",
    "# 추출된 URL 사용하여 전체 URL 완성하기\n",
    "full_url=[]\n",
    "url_cnt = 0\n",
    "for x in range(0,len(item)) :\n",
    "    url_cnt += 1\n",
    "    url = 'https://www.instagram.com' +item[x]\n",
    "    full_url.append(url)\n",
    "\n",
    "#Step 7. 각 페이지별로 그림과 해쉬태그를 수집하기\n",
    "count = 1        # 추출 데이터 건수 세기\n",
    "hash_txt = []    # 해쉬 태그 저장 \n",
    "\n",
    "# 비트맵 이미지 아이콘을 위한 대체 딕셔너리를 만든다\n",
    "import sys\n",
    "bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "\n",
    "count = 0\n",
    "for c in range(0,len(full_url)) :\n",
    "    driver.get(full_url[c])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    f = open(f_name, 'a',encoding='UTF-8')\n",
    "        \n",
    "    # 해당 페이지의 해시태그 수집\n",
    "    tags = soup.find('div','EtaWk')\n",
    "    \n",
    "    try :\n",
    "        tags_1 = tags.find_all('a')\n",
    "    except :\n",
    "        pass\n",
    "    else :\n",
    "        for d in range(0, len(tags_1)) :\n",
    "            tags = tags_1[d].get_text()\n",
    "            tags_11 = tags.translate(bmp_map)\n",
    "            tags_2 = unicodedata.normalize('NFC', tags_11)\n",
    "            \n",
    "            for i in tags_2 :\n",
    "                if i[0:1]=='#' :\n",
    "                    hash_txt.append(tags_2)\n",
    "                    print(tags_2)\n",
    "                    f.write(\"\\n\" + str(tags_2))\n",
    "    f.close()\n",
    "    count += 1\n",
    "    \n",
    "#Step 7. 요약 정보 출력하기    \n",
    "e_time = time.time( )\n",
    "t_time = e_time - s_time\n",
    "\n",
    "print(\"=\" *100)\n",
    "print(\"총 소요시간: %s 초\" %round(t_time,1))\n",
    "print(\"총 저장 건수: %s 건 \" %count)\n",
    "print(\"파일 저장 경로: %s\" %f_name)\n",
    "print(\"=\" *100)\n",
    "\n",
    "driver.close( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
